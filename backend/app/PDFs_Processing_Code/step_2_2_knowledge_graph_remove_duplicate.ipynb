{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing file: D:\\Dropbox\\29. Ampelos\\24_PED\\PED_PITT_Aaron\\backend\\PDFs_Share\\pdf_json_output\\scd_entities_relationships_total.json\n",
      "\n",
      "Entities Analysis:\n",
      "Total entities categories: 51\n",
      "  - Conditions: 3228 items\n",
      "  - Symptoms: 4490 items\n",
      "  - Care_Providers: 1178 items\n",
      "  - Diagnostic_Tests: 1331 items\n",
      "  - Risk_Factors: 4699 items\n",
      "  - Treatments: 4412 items\n",
      "  - Equipment: 17 items\n",
      "  - Complications: 1628 items\n",
      "  - Medications: 528 items\n",
      "  - Supplies: 16 items\n",
      "  - Care_Settings: 8 items\n",
      "  - Preventive_Measures: 94 items\n",
      "  - Care_Facilities: 2 items\n",
      "  - Anatomical_Features: 8 items\n",
      "  - Developmental_Milestones: 145 items\n",
      "  - Activities: 28 items\n",
      "  - Developmental_Skills: 5 items\n",
      "  - Nutrition: 39 items\n",
      "  - Safe_Foods: 8 items\n",
      "  - Behaviors: 5 items\n",
      "  - Vaccines: 5 items\n",
      "  - Safety_Measures: 14 items\n",
      "  - Developmental_Changes: 8 items\n",
      "  - Movement_Milestones: 10 items\n",
      "  - Emotional_Milestones: 3 items\n",
      "  - Social_Milestones: 10 items\n",
      "  - Recommended_Foods: 30 items\n",
      "  - Safety_Equipment: 44 items\n",
      "  - Foods: 26 items\n",
      "  - Triggers: 19 items\n",
      "  - Medical_Devices: 5 items\n",
      "  - Toxic_Substances: 11 items\n",
      "  - Risk_Groups: 2 items\n",
      "  - Protective_Factors: 104 items\n",
      "  - Support_Services: 22 items\n",
      "  - Nutrients: 3 items\n",
      "  - Dietary_Recommendations: 12 items\n",
      "  - Other_Entities: 8 items\n",
      "  - Safety_Devices: 6 items\n",
      "  - Programs: 6 items\n",
      "  - Nutritional_Elements: 9 items\n",
      "  - Care_Plans: 3 items\n",
      "  - Nutritional_Items: 10 items\n",
      "  - Preventive_Equipment: 5 items\n",
      "  - Other: 9 items\n",
      "  - Developmental_Activities: 3 items\n",
      "  - Visit_Types: 15 items\n",
      "  - Preventive_Care: 2 items\n",
      "  - Clinical_Visits: 8 items\n",
      "  - Developmental_Areas: 4 items\n",
      "  - Developmental_Stages: 6 items\n",
      "\n",
      "Relationships Analysis:\n",
      "Total relationships: 10776\n",
      "Unique sources: 2134\n",
      "Source distribution:\n",
      "  - Bright Futures Guidelines for Health... (Z-Library) (page 397): 12 relationships\n",
      "  - Breastfeeding telephone triage and ad... (Z-Library) (page 62): 10 relationships\n",
      "  - Caring for Your Baby and Young Child  Birth to Age 5 (Tanya Altmann American Academy of Pediatrics) (Z-Library) (page 37): 10 relationships\n",
      "  - Caring for Your Baby and Young Child  Birth to Age 5 (Tanya Altmann American Academy of Pediatrics) (Z-Library) (page 314): 10 relationships\n",
      "  - Caring for Your Baby and Young Child  Birth to Age 5 (Tanya Altmann American Academy of Pediatrics) (Z-Library) (page 574): 10 relationships\n",
      "Unique triples: 10776\n",
      "Unique elements:\n",
      "  - Subjects: 4744\n",
      "  - Predicates: 41\n",
      "  - Objects: 6406\n",
      "Potential reduction: 8642 relationships\n",
      "\n",
      "Deduplicating file: D:\\Dropbox\\29. Ampelos\\24_PED\\PED_PITT_Aaron\\backend\\PDFs_Share\\pdf_json_output\\scd_entities_relationships_total.json\n",
      "\n",
      "Before deduplication:\n",
      "Total relationships: 10776\n",
      "Unique sources: 2134\n",
      "\n",
      "After deduplication:\n",
      "Total relationships: 2134\n",
      "Unique sources: 2134\n",
      "\n",
      "Deduplication Summary:\n",
      "Original relationships: 10776\n",
      "Original unique sources: 2134\n",
      "After deduplication: 2134\n",
      "Final unique sources: 2134\n",
      "Removed relationships: 8642\n",
      "Reduction percentage: 80.20%\n",
      "\n",
      "Deduplicated file saved to: D:\\Dropbox\\29. Ampelos\\24_PED\\PED_PITT_Aaron\\backend\\PDFs_Share\\pdf_json_output\\scd_entities_relationships_total_deduplicated.json\n",
      "\n",
      "Verifying deduplicated file...\n",
      "\n",
      "Analyzing file: D:\\Dropbox\\29. Ampelos\\24_PED\\PED_PITT_Aaron\\backend\\PDFs_Share\\pdf_json_output\\scd_entities_relationships_total_deduplicated.json\n",
      "\n",
      "Entities Analysis:\n",
      "Total entities categories: 51\n",
      "  - Conditions: 3228 items\n",
      "  - Symptoms: 4490 items\n",
      "  - Care_Providers: 1178 items\n",
      "  - Diagnostic_Tests: 1331 items\n",
      "  - Risk_Factors: 4699 items\n",
      "  - Treatments: 4412 items\n",
      "  - Equipment: 17 items\n",
      "  - Complications: 1628 items\n",
      "  - Medications: 528 items\n",
      "  - Supplies: 16 items\n",
      "  - Care_Settings: 8 items\n",
      "  - Preventive_Measures: 94 items\n",
      "  - Care_Facilities: 2 items\n",
      "  - Anatomical_Features: 8 items\n",
      "  - Developmental_Milestones: 145 items\n",
      "  - Activities: 28 items\n",
      "  - Developmental_Skills: 5 items\n",
      "  - Nutrition: 39 items\n",
      "  - Safe_Foods: 8 items\n",
      "  - Behaviors: 5 items\n",
      "  - Vaccines: 5 items\n",
      "  - Safety_Measures: 14 items\n",
      "  - Developmental_Changes: 8 items\n",
      "  - Movement_Milestones: 10 items\n",
      "  - Emotional_Milestones: 3 items\n",
      "  - Social_Milestones: 10 items\n",
      "  - Recommended_Foods: 30 items\n",
      "  - Safety_Equipment: 44 items\n",
      "  - Foods: 26 items\n",
      "  - Triggers: 19 items\n",
      "  - Medical_Devices: 5 items\n",
      "  - Toxic_Substances: 11 items\n",
      "  - Risk_Groups: 2 items\n",
      "  - Protective_Factors: 104 items\n",
      "  - Support_Services: 22 items\n",
      "  - Nutrients: 3 items\n",
      "  - Dietary_Recommendations: 12 items\n",
      "  - Other_Entities: 8 items\n",
      "  - Safety_Devices: 6 items\n",
      "  - Programs: 6 items\n",
      "  - Nutritional_Elements: 9 items\n",
      "  - Care_Plans: 3 items\n",
      "  - Nutritional_Items: 10 items\n",
      "  - Preventive_Equipment: 5 items\n",
      "  - Other: 9 items\n",
      "  - Developmental_Activities: 3 items\n",
      "  - Visit_Types: 15 items\n",
      "  - Preventive_Care: 2 items\n",
      "  - Clinical_Visits: 8 items\n",
      "  - Developmental_Areas: 4 items\n",
      "  - Developmental_Stages: 6 items\n",
      "\n",
      "Relationships Analysis:\n",
      "Total relationships: 2134\n",
      "Unique sources: 2134\n",
      "Source distribution:\n",
      "  - Breastfeeding telephone triage and ad... (Z-Library) (page 9): 1 relationships\n",
      "  - Breastfeeding telephone triage and ad... (Z-Library) (page 10): 1 relationships\n",
      "  - Breastfeeding telephone triage and ad... (Z-Library) (page 11): 1 relationships\n",
      "  - Breastfeeding telephone triage and ad... (Z-Library) (page 13): 1 relationships\n",
      "  - Breastfeeding telephone triage and ad... (Z-Library) (page 14): 1 relationships\n",
      "Unique triples: 2134\n",
      "Unique elements:\n",
      "  - Subjects: 1356\n",
      "  - Predicates: 27\n",
      "  - Objects: 1622\n",
      "Potential reduction: 0 relationships\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "\n",
    "def analyze_deduplication(input_file):\n",
    "    \"\"\"\n",
    "    Analyze the potential impact of deduplication before processing.\n",
    "    \"\"\"\n",
    "    print(f\"\\nAnalyzing file: {input_file}\")\n",
    "    \n",
    "    try:\n",
    "        with open(input_file, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "            \n",
    "        # Check data structure and extract relationships\n",
    "        if isinstance(data, dict) and 'relationships' in data:\n",
    "            relationships = data['relationships']\n",
    "            print(f\"\\nEntities Analysis:\")\n",
    "            print(f\"Total entities categories: {len(data['entities'])}\")\n",
    "            for category, items in data['entities'].items():\n",
    "                print(f\"  - {category}: {len(items)} items\")\n",
    "        else:\n",
    "            print(\"Error: Unexpected data structure. Expected dictionary with 'relationships' key.\")\n",
    "            return None\n",
    "        \n",
    "        # Count unique sources with more detail\n",
    "        sources = set()\n",
    "        source_details = defaultdict(int)  # To count relationships per source\n",
    "        for rel in relationships:\n",
    "            if 'source' in rel:\n",
    "                source_key = (\n",
    "                    rel['source']['title'],\n",
    "                    rel['source']['page_number']\n",
    "                )\n",
    "                sources.add(source_key)\n",
    "                source_details[source_key] += 1\n",
    "        \n",
    "        # Count unique triples\n",
    "        triples = set()\n",
    "        # Count elements\n",
    "        subjects = set()\n",
    "        predicates = set()\n",
    "        objects = set()\n",
    "        \n",
    "        for rel in relationships:\n",
    "            triples.add((\n",
    "                rel['subject'],\n",
    "                rel['predicate'],\n",
    "                rel['object']\n",
    "            ))\n",
    "            subjects.add(rel['subject'])\n",
    "            predicates.add(rel['predicate'])\n",
    "            objects.add(rel['object'])\n",
    "        \n",
    "        analysis = {\n",
    "            'total_relationships': len(relationships),\n",
    "            'unique_sources': len(sources),\n",
    "            'source_details': dict(source_details),  # Convert to regular dict for storage\n",
    "            'unique_triples': len(triples),\n",
    "            'unique_subjects': len(subjects),\n",
    "            'unique_predicates': len(predicates),\n",
    "            'unique_objects': len(objects)\n",
    "        }\n",
    "        \n",
    "        print(\"\\nRelationships Analysis:\")\n",
    "        print(f\"Total relationships: {analysis['total_relationships']}\")\n",
    "        print(f\"Unique sources: {analysis['unique_sources']}\")\n",
    "        print(\"Source distribution:\")\n",
    "        for source, count in sorted(source_details.items(), key=lambda x: x[1], reverse=True)[:5]:\n",
    "            print(f\"  - {source[0]} (page {source[1]}): {count} relationships\")\n",
    "        print(f\"Unique triples: {analysis['unique_triples']}\")\n",
    "        print(f\"Unique elements:\")\n",
    "        print(f\"  - Subjects: {analysis['unique_subjects']}\")\n",
    "        print(f\"  - Predicates: {analysis['unique_predicates']}\")\n",
    "        print(f\"  - Objects: {analysis['unique_objects']}\")\n",
    "        print(f\"Potential reduction: {analysis['total_relationships'] - analysis['unique_sources']} relationships\")\n",
    "        \n",
    "        return analysis\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error analyzing file: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def deduplicate_relationships(input_file, output_file):\n",
    "    \"\"\"\n",
    "    Deduplicate relationships by keeping one relationship per unique source.\n",
    "    \"\"\"\n",
    "    print(f\"\\nDeduplicating file: {input_file}\")\n",
    "    \n",
    "    try:\n",
    "        # Read the input JSON file\n",
    "        with open(input_file, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        if not isinstance(data, dict) or 'relationships' not in data:\n",
    "            raise ValueError(\"Invalid input file structure\")\n",
    "        \n",
    "        relationships = data['relationships']\n",
    "        original_count = len(relationships)\n",
    "        \n",
    "        # Pre-deduplication source count\n",
    "        pre_sources = set()\n",
    "        for rel in relationships:\n",
    "            if 'source' in rel:\n",
    "                pre_sources.add((\n",
    "                    rel['source']['title'],\n",
    "                    rel['source']['page_number']\n",
    "                ))\n",
    "        \n",
    "        print(\"\\nBefore deduplication:\")\n",
    "        print(f\"Total relationships: {original_count}\")\n",
    "        print(f\"Unique sources: {len(pre_sources)}\")\n",
    "        \n",
    "        # Create a dictionary to store one relationship per unique source\n",
    "        source_relationships = {}\n",
    "        \n",
    "        # Process relationships to keep one per source\n",
    "        for relationship in relationships:\n",
    "            if 'source' in relationship:\n",
    "                source_key = (\n",
    "                    relationship['source']['title'],\n",
    "                    relationship['source']['page_number']\n",
    "                )\n",
    "                # Only keep the first relationship for each source\n",
    "                if source_key not in source_relationships:\n",
    "                    source_relationships[source_key] = relationship\n",
    "        \n",
    "        # Convert back to list\n",
    "        merged_relationships = list(source_relationships.values())\n",
    "        \n",
    "        # Post-deduplication source count\n",
    "        post_sources = set()\n",
    "        for rel in merged_relationships:\n",
    "            if 'source' in rel:\n",
    "                post_sources.add((\n",
    "                    rel['source']['title'],\n",
    "                    rel['source']['page_number']\n",
    "                ))\n",
    "        \n",
    "        print(\"\\nAfter deduplication:\")\n",
    "        print(f\"Total relationships: {len(merged_relationships)}\")\n",
    "        print(f\"Unique sources: {len(post_sources)}\")\n",
    "        \n",
    "        # Verify that number of relationships equals number of unique sources\n",
    "        assert len(merged_relationships) == len(post_sources), \"Number of relationships does not match number of unique sources\"\n",
    "        \n",
    "        # Create output data structure\n",
    "        output_data = {\n",
    "            'entities': data['entities'],  # Preserve original entities\n",
    "            'relationships': merged_relationships\n",
    "        }\n",
    "        \n",
    "        # Write deduplicated data\n",
    "        with open(output_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump(output_data, f, indent=2, ensure_ascii=False)\n",
    "        \n",
    "        final_count = len(merged_relationships)\n",
    "        print(f\"\\nDeduplication Summary:\")\n",
    "        print(f\"Original relationships: {original_count}\")\n",
    "        print(f\"Original unique sources: {len(pre_sources)}\")\n",
    "        print(f\"After deduplication: {final_count}\")\n",
    "        print(f\"Final unique sources: {len(post_sources)}\")\n",
    "        print(f\"Removed relationships: {original_count - final_count}\")\n",
    "        print(f\"Reduction percentage: {((original_count - final_count) / original_count * 100):.2f}%\")\n",
    "        print(f\"\\nDeduplicated file saved to: {output_file}\")\n",
    "        \n",
    "        return original_count, final_count\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error during deduplication: {str(e)}\")\n",
    "        return None, None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Define file paths\n",
    "    base_dir = Path(r\"D:\\Dropbox\\29. Ampelos\\24_PED\\PED_PITT_Aaron\\backend\\PDFs_Share\\pdf_json_output\")\n",
    "    input_file = base_dir / \"scd_entities_relationships_total.json\"\n",
    "    output_file = base_dir / \"scd_entities_relationships_total_deduplicated.json\"\n",
    "    \n",
    "    # Check if input file exists\n",
    "    if not input_file.exists():\n",
    "        print(f\"Error: Input file not found: {input_file}\")\n",
    "        exit(1)\n",
    "    \n",
    "    # First analyze the data\n",
    "    analysis = analyze_deduplication(str(input_file))\n",
    "    \n",
    "    if analysis:\n",
    "        # Proceed with deduplication without asking for user input\n",
    "        original_count, final_count = deduplicate_relationships(str(input_file), str(output_file))\n",
    "        \n",
    "        if original_count and final_count:\n",
    "            # Verify the deduplicated file\n",
    "            print(\"\\nVerifying deduplicated file...\")\n",
    "            verify_analysis = analyze_deduplication(str(output_file))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ped",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
