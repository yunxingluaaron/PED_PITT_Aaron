{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8cbe98e",
   "metadata": {},
   "source": [
    "### 05.20.2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d6f969",
   "metadata": {},
   "source": [
    "#### 这个代码的作用是清理 excel 文件 “recovered_utf8_for_excel.csv”\n",
    "#### 之前的问题是，旧文件有很多行，将近两万行有多余4个 fields, 这样会导致加载报错\n",
    "#### 这个代码的目的就是把多余的列，合并到第四列，然后消除报错\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5afc1c",
   "metadata": {},
   "source": [
    "#### 1. 把所有的row 多余4个 fields 的都合并成只有4个fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7760eda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import csv\n",
    "import os\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "# Define paths\n",
    "input_csv_path = 'recovered_utf8_for_excel.csv'\n",
    "output_csv_path = 'cleaned_recovered_utf8_for_excel.csv'\n",
    "\n",
    "# Step 1: Count problematic rows\n",
    "def count_problematic_rows(input_path, expected_fields=4):\n",
    "    \"\"\"\n",
    "    Count rows with incorrect number of fields and log their details.\n",
    "    \n",
    "    Args:\n",
    "        input_path (str): Path to the input CSV file\n",
    "        expected_fields (int): Expected number of fields per row\n",
    "    Returns:\n",
    "        tuple: (problematic_rows, field_counts)\n",
    "            - problematic_rows: List of tuples (line_number, row, field_count)\n",
    "            - field_counts: Counter of field counts\n",
    "    \"\"\"\n",
    "    problematic_rows = []\n",
    "    field_counts = Counter()\n",
    "    \n",
    "    with open(input_path, 'r', encoding='utf-8') as infile:\n",
    "        reader = csv.reader(infile)\n",
    "        for line_num, row in enumerate(reader, 1):\n",
    "            field_count = len(row)\n",
    "            field_counts[field_count] += 1\n",
    "            if field_count != expected_fields:\n",
    "                problematic_rows.append((line_num, row, field_count))\n",
    "    \n",
    "    return problematic_rows, field_counts\n",
    "\n",
    "# Step 2: Clean CSV by merging extra fields into the 4th field\n",
    "def clean_csv(input_path, output_path, expected_fields=4):\n",
    "    \"\"\"\n",
    "    Clean the CSV by merging extra fields into the 4th field for rows with >4 fields.\n",
    "    Rows with <4 fields are padded with empty strings.\n",
    "    \n",
    "    Args:\n",
    "        input_path (str): Path to the input CSV file\n",
    "        output_path (str): Path to save the cleaned CSV\n",
    "        expected_fields (int): Expected number of fields per row\n",
    "    \"\"\"\n",
    "    with open(input_path, 'r', encoding='utf-8') as infile, \\\n",
    "         open(output_path, 'w', encoding='utf-8', newline='') as outfile:\n",
    "        reader = csv.reader(infile)\n",
    "        writer = csv.writer(outfile, quoting=csv.QUOTE_ALL)\n",
    "        \n",
    "        for row in reader:\n",
    "            if len(row) > expected_fields:\n",
    "                # Merge all fields after the 3rd into the 4th field\n",
    "                cleaned_row = row[:3] + [','.join(row[3:])]\n",
    "            elif len(row) < expected_fields:\n",
    "                # Pad with empty strings if fewer fields\n",
    "                cleaned_row = row + [''] * (expected_fields - len(row))\n",
    "            else:\n",
    "                # Row is already correct\n",
    "                cleaned_row = row\n",
    "            writer.writerow(cleaned_row)\n",
    "\n",
    "# Step 3: Verify the cleaned CSV\n",
    "def verify_cleaned_csv(output_path, expected_fields=4):\n",
    "    \"\"\"\n",
    "    Verify that the cleaned CSV has the correct number of fields in all rows.\n",
    "    \n",
    "    Args:\n",
    "        output_path (str): Path to the cleaned CSV\n",
    "        expected_fields (int): Expected number of fields per row\n",
    "    Returns:\n",
    "        bool: True if all rows have the expected number of fields, False otherwise\n",
    "    \"\"\"\n",
    "    with open(output_path, 'r', encoding='utf-8') as infile:\n",
    "        reader = csv.reader(infile)\n",
    "        for line_num, row in enumerate(reader, 1):\n",
    "            if len(row) != expected_fields:\n",
    "                print(f\"Verification failed: Line {line_num} has {len(row)} fields\")\n",
    "                return False\n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ddd8717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Analyzing problematic rows...\n",
      "\n",
      "Field count distribution:\n",
      "Rows with 1 fields: 12467\n",
      "Rows with 2 fields: 1824\n",
      "Rows with 3 fields: 1925\n",
      "Rows with 4 fields: 84344\n",
      "Rows with 5 fields: 3233\n",
      "Rows with 6 fields: 1924\n",
      "Rows with 7 fields: 1613\n",
      "Rows with 8 fields: 1345\n",
      "Rows with 9 fields: 1099\n",
      "Rows with 10 fields: 968\n",
      "Rows with 11 fields: 841\n",
      "Rows with 12 fields: 637\n",
      "Rows with 13 fields: 553\n",
      "Rows with 14 fields: 472\n",
      "Rows with 15 fields: 420\n",
      "Rows with 16 fields: 376\n",
      "Rows with 17 fields: 342\n",
      "Rows with 18 fields: 302\n",
      "Rows with 19 fields: 238\n",
      "Rows with 20 fields: 225\n",
      "Rows with 21 fields: 170\n",
      "Rows with 22 fields: 176\n",
      "Rows with 23 fields: 119\n",
      "Rows with 24 fields: 128\n",
      "Rows with 25 fields: 117\n",
      "Rows with 26 fields: 89\n",
      "Rows with 27 fields: 90\n",
      "Rows with 28 fields: 57\n",
      "Rows with 29 fields: 76\n",
      "Rows with 30 fields: 58\n",
      "Rows with 31 fields: 54\n",
      "Rows with 32 fields: 46\n",
      "Rows with 33 fields: 30\n",
      "Rows with 34 fields: 31\n",
      "Rows with 35 fields: 34\n",
      "Rows with 36 fields: 22\n",
      "Rows with 37 fields: 18\n",
      "Rows with 38 fields: 10\n",
      "Rows with 39 fields: 28\n",
      "Rows with 40 fields: 22\n",
      "Rows with 41 fields: 15\n",
      "Rows with 42 fields: 23\n",
      "Rows with 43 fields: 14\n",
      "Rows with 44 fields: 14\n",
      "Rows with 45 fields: 11\n",
      "Rows with 46 fields: 11\n",
      "Rows with 47 fields: 10\n",
      "Rows with 48 fields: 5\n",
      "Rows with 49 fields: 13\n",
      "Rows with 50 fields: 13\n",
      "Rows with 51 fields: 7\n",
      "Rows with 52 fields: 6\n",
      "Rows with 53 fields: 11\n",
      "Rows with 54 fields: 9\n",
      "Rows with 55 fields: 3\n",
      "Rows with 56 fields: 2\n",
      "Rows with 57 fields: 6\n",
      "Rows with 58 fields: 11\n",
      "Rows with 59 fields: 1\n",
      "Rows with 60 fields: 6\n",
      "Rows with 61 fields: 13\n",
      "Rows with 62 fields: 5\n",
      "Rows with 63 fields: 4\n",
      "Rows with 64 fields: 3\n",
      "Rows with 65 fields: 11\n",
      "Rows with 66 fields: 6\n",
      "Rows with 67 fields: 3\n",
      "Rows with 68 fields: 5\n",
      "Rows with 69 fields: 6\n",
      "Rows with 70 fields: 7\n",
      "Rows with 71 fields: 1\n",
      "Rows with 72 fields: 5\n",
      "Rows with 73 fields: 8\n",
      "Rows with 74 fields: 3\n",
      "Rows with 75 fields: 1\n",
      "Rows with 76 fields: 2\n",
      "Rows with 79 fields: 3\n",
      "Rows with 80 fields: 1\n",
      "Rows with 81 fields: 4\n",
      "Rows with 82 fields: 5\n",
      "Rows with 83 fields: 3\n",
      "Rows with 84 fields: 1\n",
      "Rows with 85 fields: 2\n",
      "Rows with 86 fields: 3\n",
      "Rows with 88 fields: 1\n",
      "Rows with 89 fields: 1\n",
      "Rows with 90 fields: 4\n",
      "Rows with 91 fields: 2\n",
      "Rows with 92 fields: 1\n",
      "Rows with 94 fields: 1\n",
      "Rows with 95 fields: 3\n",
      "Rows with 96 fields: 2\n",
      "Rows with 97 fields: 3\n",
      "Rows with 98 fields: 2\n",
      "Rows with 99 fields: 4\n",
      "Rows with 100 fields: 4\n",
      "Rows with 102 fields: 1\n",
      "Rows with 104 fields: 1\n",
      "Rows with 105 fields: 1\n",
      "Rows with 108 fields: 2\n",
      "Rows with 111 fields: 1\n",
      "Rows with 112 fields: 2\n",
      "Rows with 113 fields: 1\n",
      "Rows with 114 fields: 1\n",
      "Rows with 117 fields: 3\n",
      "Rows with 118 fields: 2\n",
      "Rows with 121 fields: 1\n",
      "Rows with 122 fields: 2\n",
      "Rows with 124 fields: 2\n",
      "Rows with 125 fields: 1\n",
      "Rows with 126 fields: 1\n",
      "Rows with 128 fields: 1\n",
      "Rows with 130 fields: 1\n",
      "Rows with 135 fields: 1\n",
      "Rows with 136 fields: 1\n",
      "Rows with 140 fields: 1\n",
      "Rows with 141 fields: 2\n",
      "Rows with 142 fields: 1\n",
      "Rows with 144 fields: 1\n",
      "Rows with 148 fields: 4\n",
      "Rows with 151 fields: 1\n",
      "Rows with 161 fields: 2\n",
      "Rows with 168 fields: 1\n",
      "Rows with 179 fields: 2\n",
      "Rows with 183 fields: 1\n",
      "Rows with 187 fields: 1\n",
      "Rows with 207 fields: 2\n",
      "Rows with 235 fields: 1\n",
      "Rows with 237 fields: 1\n",
      "Rows with 252 fields: 1\n",
      "Rows with 254 fields: 2\n",
      "Rows with 260 fields: 1\n",
      "Rows with 270 fields: 1\n",
      "Rows with 293 fields: 1\n",
      "Rows with 302 fields: 1\n",
      "Rows with 340 fields: 1\n",
      "Rows with 343 fields: 1\n",
      "Rows with 346 fields: 1\n",
      "Rows with 419 fields: 2\n",
      "Rows with 485 fields: 1\n",
      "Rows with 505 fields: 1\n",
      "Rows with 561 fields: 2\n",
      "Total problematic rows: 32566\n",
      "\n",
      "Sample problematic rows (first 5):\n",
      "Line 196: 6 fields - ['新生儿科', '新生儿黄疸要怎么治疗合适', '宝宝15个月精神状态不好，感觉到宝宝生病了，请问：新生儿黄疸要怎么治疗合适', '\"这是大便的结果啊，仔细观察看一看，大便有极少量白细胞，提示肠道细菌感染，大于19为病理性的', '1周左右到医院服查', '看一看效果。不要有任何的心理压力，保持愉快的心情，而且期间要注意多休息，同时饮食也要保持清单，避免油腻和辛辣，这样对你自己和腹中的胎儿都是有好处的。\"']\n",
      "Line 203: 6 fields - ['神经内科', '要怎么去判断患者是不是有脑瘫', '女今年31岁，精神状态最近不是很好，也不知道怎么回事，请问：要怎么去判断患者是不是有脑瘫？', '\"脑瘫患儿的生长发育较为缓慢，具体表现在语言和活动上，绝大多数的脑瘫患儿发音不清楚，半年大的脑瘫患儿绝大多数不能够无限制的抓握，对于家人的声音不敏感，并且经常面部没表情，可以做脑部的ct诊断。另外，在日常生活中患者要均衡补充身体营养', '多做做一些有氧运动来锻炼身体', '并且要保持愉快的心情，以此来增强体质加快康复速度。\"']\n",
      "Line 2047: 6 fields - ['新生儿科', '缺铁性贫血的主要原因是什么', '女今年28岁，我一直也在治这个病，也都在吃药，但是一直不见好转，我也很烦，用了很多方法也不行，请问：缺铁性贫血的主要原因是什么？', '\"会引来缺铁性贫血的主要原因，就是缺铁的原因致使的，应该是平时的饮食问题，像是饮食还不够有营养，又或是因为长时间不吃早饭的原因致使的，建议你平时最好是多吃一些补充铁的食物。另外，在日常生活中患者要均衡补充身体营养', '多做做一些有氧运动来锻炼身体', '并且要保持愉快的心情，以此来增强体质加快康复速度。\"']\n",
      "Line 2054: 6 fields - ['神经内科', '较常见的小儿脑瘫症状怎能能缓解', '女今年2岁，我一直也在治这个病，也都在吃药，但是一直不见好转，我也很烦，用了很多方法也不行，请问：较常见的小儿脑瘫症状怎能能缓解', '\"脑瘫是自分娩已经开始至婴儿期非进行性脑损伤和生长发育缺点所致的综合征，主要表现出为运动障碍及姿势异常。意见建议去医院做专业的康复治疗，抱括语言肢体特训，制做个专业的特训计划，脑瘫会有很大的稳定。另外，在日常生活中患者要均衡补充身体营养', '多做做一些有氧运动来锻炼身体', '并且要保持愉快的心情，以此来增强体质加快康复速度。\"']\n",
      "Line 2057: 6 fields - ['新生儿科', '新生儿脑瘫的早期症状有什么', '女今年2岁，我也不知道当初我为什么会有这个病，因为当初我也没去注意这件事，知道我身体不适的时候才去查身体，这病已经开始影响我的生活。请问：新生儿脑瘫的早期症状有什么？', '\"脑瘫早期最明显的症状就是不会抬眼，还会有斜视，无伫立对此或举步，易惊，哭啼远不止，厌乳和深度睡眠困难等。除了就是过度僵硬或是瘫倒。大腿不易外展，而且在洗澡时再次出现四肢僵硬，并且婴儿不喜欢泡澡。另外，在日常生活中患者要均衡补充身体营养', '多做做一些有氧运动来锻炼身体', '并且要保持愉快的心情，以此来增强体质加快康复速度。\"']\n",
      "\n",
      "Step 2: Cleaning the CSV...\n",
      "\n",
      "Step 3: Verifying the cleaned CSV...\n",
      "Success: All rows in cleaned_recovered_utf8_for_excel.csv have exactly 4 fields.\n",
      "\n",
      "Preview of cleaned CSV:\n",
      "  ﻿department        title                                                ask  \\\n",
      "0       营养保健科  小儿肥胖超重该如何治疗  女宝宝，刚7岁，这一年，察觉到，我家孩子身上肉很多，而且，食量非常的大，平时都不喜欢吃去玩，...   \n",
      "1       营养保健科  小儿肥胖超重该怎样医治  男孩子，刚4岁，最近，发现，我家孩子体重要比别的孩子重很多，而且，最近越来越能吃了，还特别的...   \n",
      "2       营养保健科  小儿肥胖能吃该如何治疗  男宝，已经5岁，今年，察觉到，孩子身上越来越肉乎了，同时，吃的饭也比一般孩子多，平时都不喜欢...   \n",
      "3       营养保健科  小儿肥胖能吃该如何医治  女宝宝，目前2岁，近期，观察到，我家孩子越来越胖了，而且，吃起来好像也特别不节制，叫他运动也...   \n",
      "4       营养保健科   小儿肥胖懒应怎样治疗  男孩，7岁，上小学了，这一年，观察到，孩子身上越来越肉乎了，而且，食量非常的大，平时都不喜欢...   \n",
      "\n",
      "                                              answer  \n",
      "0  孩子出现肥胖症的情况。家长要通过孩子运功和健康的饮食来缓解他的症状，可以先让他做一些有氧运动...  \n",
      "1  孩子一旦患上肥胖症家长要先通过运动和饮食来改变孩子的情况，要让孩子做一些他这个年龄段能做的运...  \n",
      "2  当孩子患上肥胖症的时候家长可以增加孩子的运动量和控制他的饮食来改变症状，像游泳，爬坡这类游泳...  \n",
      "3  当孩子患上肥胖症的时候家长可以增加孩子的运动量和控制他的饮食来改变症状，家长要监督孩子做一些...  \n",
      "4  当孩子患上肥胖症的时候家长可以增加孩子的运动量和控制他的饮食来改变症状，给孩子在承受范围内安...  \n"
     ]
    }
   ],
   "source": [
    "# Run the analysis and cleaning\n",
    "print(\"Step 1: Analyzing problematic rows...\")\n",
    "problematic_rows, field_counts = count_problematic_rows(input_csv_path)\n",
    "\n",
    "# Print summary\n",
    "print(\"\\nField count distribution:\")\n",
    "for field_count, count in sorted(field_counts.items()):\n",
    "    print(f\"Rows with {field_count} fields: {count}\")\n",
    "print(f\"Total problematic rows: {len(problematic_rows)}\")\n",
    "print(\"\\nSample problematic rows (first 5):\")\n",
    "for line_num, row, field_count in problematic_rows[:5]:\n",
    "    print(f\"Line {line_num}: {field_count} fields - {row}\")\n",
    "\n",
    "# Clean the CSV\n",
    "print(\"\\nStep 2: Cleaning the CSV...\")\n",
    "clean_csv(input_csv_path, output_csv_path)\n",
    "\n",
    "# Verify the cleaned CSV\n",
    "print(\"\\nStep 3: Verifying the cleaned CSV...\")\n",
    "if verify_cleaned_csv(output_csv_path):\n",
    "    print(f\"Success: All rows in {output_csv_path} have exactly 4 fields.\")\n",
    "else:\n",
    "    print(f\"Error: Some rows in {output_csv_path} still have incorrect field counts.\")\n",
    "\n",
    "# Optional: Preview the cleaned CSV with pandas\n",
    "print(\"\\nPreview of cleaned CSV:\")\n",
    "df = pd.read_csv(output_csv_path, quoting=csv.QUOTE_ALL, encoding='utf-8')\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53db7be8",
   "metadata": {},
   "source": [
    "### 2. Check the new generated data has only 4 fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17083b74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verifying CSV: cleaned_recovered_utf8_for_excel.csv\n",
      "\n",
      "Field count distribution:\n",
      "Rows with 4 fields: 116910\n",
      "\n",
      "Success: All rows in cleaned_recovered_utf8_for_excel.csv have exactly 4 fields.\n",
      "\n",
      "Preview of cleaned CSV:\n",
      "  ﻿department        title                                                ask  \\\n",
      "0       营养保健科  小儿肥胖超重该如何治疗  女宝宝，刚7岁，这一年，察觉到，我家孩子身上肉很多，而且，食量非常的大，平时都不喜欢吃去玩，...   \n",
      "1       营养保健科  小儿肥胖超重该怎样医治  男孩子，刚4岁，最近，发现，我家孩子体重要比别的孩子重很多，而且，最近越来越能吃了，还特别的...   \n",
      "2       营养保健科  小儿肥胖能吃该如何治疗  男宝，已经5岁，今年，察觉到，孩子身上越来越肉乎了，同时，吃的饭也比一般孩子多，平时都不喜欢...   \n",
      "3       营养保健科  小儿肥胖能吃该如何医治  女宝宝，目前2岁，近期，观察到，我家孩子越来越胖了，而且，吃起来好像也特别不节制，叫他运动也...   \n",
      "4       营养保健科   小儿肥胖懒应怎样治疗  男孩，7岁，上小学了，这一年，观察到，孩子身上越来越肉乎了，而且，食量非常的大，平时都不喜欢...   \n",
      "\n",
      "                                              answer  \n",
      "0  孩子出现肥胖症的情况。家长要通过孩子运功和健康的饮食来缓解他的症状，可以先让他做一些有氧运动...  \n",
      "1  孩子一旦患上肥胖症家长要先通过运动和饮食来改变孩子的情况，要让孩子做一些他这个年龄段能做的运...  \n",
      "2  当孩子患上肥胖症的时候家长可以增加孩子的运动量和控制他的饮食来改变症状，像游泳，爬坡这类游泳...  \n",
      "3  当孩子患上肥胖症的时候家长可以增加孩子的运动量和控制他的饮食来改变症状，家长要监督孩子做一些...  \n",
      "4  当孩子患上肥胖症的时候家长可以增加孩子的运动量和控制他的饮食来改变症状，给孩子在承受范围内安...  \n",
      "\n",
      "Total rows: 116909\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import csv\n",
    "import os\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "# Define path to the cleaned CSV\n",
    "cleaned_csv_path = 'cleaned_recovered_utf8_for_excel.csv'\n",
    "\n",
    "# Step 1: Verify the number of fields in each row\n",
    "def verify_csv_fields(csv_path, expected_fields=4):\n",
    "    \"\"\"\n",
    "    Verify that all rows in the CSV have the expected number of fields.\n",
    "    \n",
    "    Args:\n",
    "        csv_path (str): Path to the CSV file\n",
    "        expected_fields (int): Expected number of fields per row\n",
    "    Returns:\n",
    "        tuple: (all_valid, field_counts, problematic_rows)\n",
    "            - all_valid: True if all rows have expected_fields, False otherwise\n",
    "            - field_counts: Counter of field counts\n",
    "            - problematic_rows: List of tuples (line_number, row, field_count) for problematic rows\n",
    "    \"\"\"\n",
    "    problematic_rows = []\n",
    "    field_counts = Counter()\n",
    "    \n",
    "    with open(csv_path, 'r', encoding='utf-8') as infile:\n",
    "        reader = csv.reader(infile)\n",
    "        for line_num, row in enumerate(reader, 1):\n",
    "            field_count = len(row)\n",
    "            field_counts[field_count] += 1\n",
    "            if field_count != expected_fields:\n",
    "                problematic_rows.append((line_num, row, field_count))\n",
    "    \n",
    "    all_valid = len(problematic_rows) == 0\n",
    "    return all_valid, field_counts, problematic_rows\n",
    "\n",
    "# Step 2: Run the verification\n",
    "print(f\"Verifying CSV: {cleaned_csv_path}\")\n",
    "if not os.path.exists(cleaned_csv_path):\n",
    "    print(f\"Error: File not found at {cleaned_csv_path}\")\n",
    "else:\n",
    "    all_valid, field_counts, problematic_rows = verify_csv_fields(cleaned_csv_path)\n",
    "\n",
    "    # Print field count distribution\n",
    "    print(\"\\nField count distribution:\")\n",
    "    for field_count, count in sorted(field_counts.items()):\n",
    "        print(f\"Rows with {field_count} fields: {count}\")\n",
    "\n",
    "    # Report results\n",
    "    if all_valid:\n",
    "        print(f\"\\nSuccess: All rows in {cleaned_csv_path} have exactly 4 fields.\")\n",
    "    else:\n",
    "        print(f\"\\nError: Found {len(problematic_rows)} rows with incorrect field counts.\")\n",
    "        print(\"Sample problematic rows (first 5):\")\n",
    "        for line_num, row, field_count in problematic_rows[:5]:\n",
    "            print(f\"Line {line_num}: {field_count} fields - {row}\")\n",
    "\n",
    "    # Step 3: Preview the cleaned CSV\n",
    "    print(\"\\nPreview of cleaned CSV:\")\n",
    "    try:\n",
    "        df = pd.read_csv(cleaned_csv_path, quoting=csv.QUOTE_ALL, encoding='utf-8')\n",
    "        print(df.head())\n",
    "        print(f\"\\nTotal rows: {len(df)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading CSV with pandas: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b37114b",
   "metadata": {},
   "source": [
    "#### 3. 在合并成只有 4个 fields 之后，清理row 含有任何的 missing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "447aed05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Inspecting the original cleaned CSV...\n",
      "Inspecting cleaned_recovered_utf8_for_excel.csv...\n",
      "\n",
      "First 5 lines (raw):\n",
      "Line 1: \"﻿department\",\"title\",\"ask\",\"answer\"\n",
      "Line 2: \"营养保健科\",\"小儿肥胖超重该如何治疗\",\"女宝宝，刚7岁，这一年，察觉到，我家孩子身上肉很多，而且，食量非常的大，平时都不喜欢吃去玩，请问：小儿肥胖超重该如何治疗。\",\"孩子出现肥胖症的情况。家长要通过孩子运功和健康的饮食来缓解他的症状，可以先让他做一些有氧运动，比如慢跑，爬坡，游泳等，并且饮食上孩子多吃黄瓜，胡萝卜，菠菜等，禁止孩子吃一些油炸食品和干果类食物，这些都是干热量高脂肪的食物，而且不要让孩子总是吃完就躺在床上不动，家长在治疗小儿肥胖期间如果孩子情况严重就要及时去医院在医生的指导下给孩子治疗。\"\n",
      "Line 3: \"营养保健科\",\"小儿肥胖超重该怎样医治\",\"男孩子，刚4岁，最近，发现，我家孩子体重要比别的孩子重很多，而且，最近越来越能吃了，还特别的懒，请问：小儿肥胖超重该怎样医治。\",\"孩子一旦患上肥胖症家长要先通过运动和饮食来改变孩子的情况，要让孩子做一些他这个年龄段能做的运动，如游泳，慢跑等，要给孩子多吃一些像苹果，猕猴桃，胡萝卜等食物，禁止孩子吃高热量，高脂肪的食物，像蛋糕，干果，曲奇饼干等，严格的控制孩子的饮食，不要让他暴饮暴食，多运动对改变孩子肥胖都是有好处的，在治疗小儿肥胖期间如果情况严重，建议家长先带孩子去医院检查一下孩子肥胖症的原因在针对性的治疗。\"\n",
      "Line 4: \"营养保健科\",\"小儿肥胖能吃该如何治疗\",\"男宝，已经5岁，今年，察觉到，孩子身上越来越肉乎了，同时，吃的饭也比一般孩子多，平时都不喜欢吃去玩，请问：小儿肥胖能吃该如何治疗。\",\"当孩子患上肥胖症的时候家长可以增加孩子的运动量和控制他的饮食来改变症状，像游泳，爬坡这类游泳运动对肥胖的症状都很好的效果，像冬瓜，西红柿这样高纤维的蔬菜要多吃一些，孩子不可以吃像蛋糕，夏威夷果这些高热量的食物，而且不要让孩子总是吃完就躺在床上不动，家长在治疗小儿肥胖期间如果孩子情况严重就要及时去医院在医生的指导下给孩子治疗。\"\n",
      "Line 5: \"营养保健科\",\"小儿肥胖能吃该如何医治\",\"女宝宝，目前2岁，近期，观察到，我家孩子越来越胖了，而且，吃起来好像也特别不节制，叫他运动也不愿意，请问：小儿肥胖能吃该如何医治。\",\"当孩子患上肥胖症的时候家长可以增加孩子的运动量和控制他的饮食来改变症状，家长要监督孩子做一些有氧运动像慢跑，游泳等，要给孩子多吃一些像苹果，猕猴桃，胡萝卜等食物，一定要禁止孩子吃蛋糕，板栗这些高热量的食物，生活中不要让孩子在床上吃零食或者吃完就躺着这些不好的习惯也会让脂肪堆积，肥胖症治疗期间家长要根据孩子的情况进行合理的治疗，如果病情严重的话一定要去医院查明原因针对治疗。\"\n",
      "\n",
      "Pandas DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 116909 entries, 0 to 116908\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count   Dtype \n",
      "---  ------       --------------   ----- \n",
      " 0   ﻿department  114175 non-null  object\n",
      " 1   title        104423 non-null  object\n",
      " 2   ask          102609 non-null  object\n",
      " 3   answer       100685 non-null  object\n",
      "dtypes: object(4)\n",
      "memory usage: 3.6+ MB\n",
      "None\n",
      "\n",
      "First 5 rows:\n",
      "  ﻿department        title                                                ask  \\\n",
      "0       营养保健科  小儿肥胖超重该如何治疗  女宝宝，刚7岁，这一年，察觉到，我家孩子身上肉很多，而且，食量非常的大，平时都不喜欢吃去玩，...   \n",
      "1       营养保健科  小儿肥胖超重该怎样医治  男孩子，刚4岁，最近，发现，我家孩子体重要比别的孩子重很多，而且，最近越来越能吃了，还特别的...   \n",
      "2       营养保健科  小儿肥胖能吃该如何治疗  男宝，已经5岁，今年，察觉到，孩子身上越来越肉乎了，同时，吃的饭也比一般孩子多，平时都不喜欢...   \n",
      "3       营养保健科  小儿肥胖能吃该如何医治  女宝宝，目前2岁，近期，观察到，我家孩子越来越胖了，而且，吃起来好像也特别不节制，叫他运动也...   \n",
      "4       营养保健科   小儿肥胖懒应怎样治疗  男孩，7岁，上小学了，这一年，观察到，孩子身上越来越肉乎了，而且，食量非常的大，平时都不喜欢...   \n",
      "\n",
      "                                              answer  \n",
      "0  孩子出现肥胖症的情况。家长要通过孩子运功和健康的饮食来缓解他的症状，可以先让他做一些有氧运动...  \n",
      "1  孩子一旦患上肥胖症家长要先通过运动和饮食来改变孩子的情况，要让孩子做一些他这个年龄段能做的运...  \n",
      "2  当孩子患上肥胖症的时候家长可以增加孩子的运动量和控制他的饮食来改变症状，像游泳，爬坡这类游泳...  \n",
      "3  当孩子患上肥胖症的时候家长可以增加孩子的运动量和控制他的饮食来改变症状，家长要监督孩子做一些...  \n",
      "4  当孩子患上肥胖症的时候家长可以增加孩子的运动量和控制他的饮食来改变症状，给孩子在承受范围内安...  \n",
      "\n",
      "Actual columns: ['\\ufeffdepartment', 'title', 'ask', 'answer']\n",
      "\n",
      "Missing values:\n",
      "﻿department: 2734\n",
      "title: 12486\n",
      "ask: 14300\n",
      "answer: 16224\n",
      "Total rows: 116909\n",
      "\n",
      "Step 2: Removing rows with missing values and fixing CSV...\n",
      "\n",
      "New CSV saved to no_missing_cleaned_recovered_utf8_for_excel.csv\n",
      "Original rows: 116909\n",
      "Rows after removing missing values: 100679\n",
      "Rows removed: 16230\n",
      "New columns: ['department', 'extra', 'ask', 'answer']\n",
      "\n",
      "Step 3: Verifying the new CSV...\n",
      "\n",
      "Verifying no_missing_cleaned_recovered_utf8_for_excel.csv...\n",
      "Headers: ['department', 'extra', 'ask', 'answer']\n",
      "Total rows (including header): 100680\n",
      "All rows have exactly 4 fields.\n",
      "\n",
      "Pandas DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100679 entries, 0 to 100678\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   department  100679 non-null  object\n",
      " 1   extra       100679 non-null  object\n",
      " 2   ask         100679 non-null  object\n",
      " 3   answer      100679 non-null  object\n",
      "dtypes: object(4)\n",
      "memory usage: 3.1+ MB\n",
      "None\n",
      "\n",
      "Actual columns: ['department', 'extra', 'ask', 'answer']\n",
      "Expected columns: ['department', 'ask', 'answer', 'extra']\n",
      "Total rows: 100679\n",
      "\n",
      "Missing values:\n",
      "department: 0\n",
      "ask: 0\n",
      "answer: 0\n",
      "extra: 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import csv\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define paths\n",
    "input_csv_path = 'cleaned_recovered_utf8_for_excel.csv'\n",
    "output_csv_path = 'no_missing_cleaned_recovered_utf8_for_excel.csv'\n",
    "\n",
    "# Step 1: Inspect the original cleaned CSV\n",
    "def inspect_csv(csv_path):\n",
    "    \"\"\"\n",
    "    Inspect the CSV to confirm structure and missing values.\n",
    "    \"\"\"\n",
    "    print(f\"Inspecting {csv_path}...\")\n",
    "    try:\n",
    "        # Read first few lines\n",
    "        with open(csv_path, 'r', encoding='utf-8-sig') as infile:\n",
    "            print(\"\\nFirst 5 lines (raw):\")\n",
    "            for i, line in enumerate(infile, 1):\n",
    "                if i > 5:\n",
    "                    break\n",
    "                print(f\"Line {i}: {line.strip()}\")\n",
    "        \n",
    "        # Load with pandas\n",
    "        df = pd.read_csv(csv_path, encoding='utf-8-sig', quoting=csv.QUOTE_ALL)\n",
    "        print(\"\\nPandas DataFrame Info:\")\n",
    "        print(df.info())\n",
    "        print(\"\\nFirst 5 rows:\")\n",
    "        print(df.head())\n",
    "        print(f\"\\nActual columns: {df.columns.tolist()}\")\n",
    "        print(f\"\\nMissing values:\")\n",
    "        for col in df.columns:\n",
    "            print(f\"{col}: {df[col].isna().sum()}\")\n",
    "        print(f\"Total rows: {len(df)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error inspecting CSV: {str(e)}\")\n",
    "\n",
    "# Step 2: Remove rows with missing values and fix column names\n",
    "def remove_missing_values_csv(input_path, output_path):\n",
    "    \"\"\"\n",
    "    Remove rows with missing values in department, ask, or answer, and fix column names.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load the CSV with pandas, handling BOM\n",
    "        df = pd.read_csv(input_path, encoding='utf-8-sig', quoting=csv.QUOTE_ALL)\n",
    "        \n",
    "        # Rename columns to match expected names\n",
    "        rename_dict = {\n",
    "            '\\ufeffdepartment': 'department',\n",
    "            'title': 'extra',\n",
    "            'ask': 'ask',\n",
    "            'answer': 'answer'\n",
    "        }\n",
    "        df = df.rename(columns=rename_dict)\n",
    "        \n",
    "        # Remove rows with missing values in critical columns\n",
    "        original_rows = len(df)\n",
    "        df = df.dropna(subset=['department', 'ask', 'answer'])\n",
    "        removed_rows = original_rows - len(df)\n",
    "        \n",
    "        # Ensure extra column is not null\n",
    "        df['extra'] = df['extra'].fillna('')\n",
    "        \n",
    "        # Save the new CSV\n",
    "        df.to_csv(output_path, index=False, encoding='utf-8', quoting=csv.QUOTE_ALL)\n",
    "        print(f\"\\nNew CSV saved to {output_path}\")\n",
    "        print(f\"Original rows: {original_rows}\")\n",
    "        print(f\"Rows after removing missing values: {len(df)}\")\n",
    "        print(f\"Rows removed: {removed_rows}\")\n",
    "        print(f\"New columns: {df.columns.tolist()}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing CSV: {str(e)}\")\n",
    "\n",
    "# Step 3: Verify the new CSV\n",
    "def verify_new_csv(csv_path, expected_fields=4, expected_columns=['department', 'ask', 'answer', 'extra']):\n",
    "    \"\"\"\n",
    "    Verify that the new CSV has no missing values and correct structure.\n",
    "    \"\"\"\n",
    "    print(f\"\\nVerifying {csv_path}...\")\n",
    "    try:\n",
    "        # Check field counts with csv.reader\n",
    "        with open(csv_path, 'r', encoding='utf-8') as infile:\n",
    "            reader = csv.reader(infile)\n",
    "            headers = next(reader, None)\n",
    "            row_count = 1\n",
    "            problematic_rows = []\n",
    "            for line_num, row in enumerate(reader, 2):\n",
    "                row_count += 1\n",
    "                if len(row) != expected_fields:\n",
    "                    problematic_rows.append((line_num, row, len(row)))\n",
    "            \n",
    "            print(f\"Headers: {headers}\")\n",
    "            print(f\"Total rows (including header): {row_count}\")\n",
    "            if problematic_rows:\n",
    "                print(f\"Found {len(problematic_rows)} problematic rows:\")\n",
    "                for line_num, row, field_count in problematic_rows[:5]:\n",
    "                    print(f\"Line {line_num}: {field_count} fields - {row}\")\n",
    "            else:\n",
    "                print(\"All rows have exactly 4 fields.\")\n",
    "        \n",
    "        # Check with pandas\n",
    "        df = pd.read_csv(csv_path, encoding='utf-8', quoting=csv.QUOTE_ALL)\n",
    "        print(\"\\nPandas DataFrame Info:\")\n",
    "        print(df.info())\n",
    "        print(f\"\\nActual columns: {df.columns.tolist()}\")\n",
    "        print(f\"Expected columns: {expected_columns}\")\n",
    "        print(f\"Total rows: {len(df)}\")\n",
    "        print(f\"\\nMissing values:\")\n",
    "        for col in expected_columns:\n",
    "            print(f\"{col}: {df[col].isna().sum()}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error verifying CSV: {str(e)}\")\n",
    "\n",
    "# Run the inspection, processing, and verification\n",
    "print(\"Step 1: Inspecting the original cleaned CSV...\")\n",
    "inspect_csv(input_csv_path)\n",
    "\n",
    "print(\"\\nStep 2: Removing rows with missing values and fixing CSV...\")\n",
    "remove_missing_values_csv(input_csv_path, output_csv_path)\n",
    "\n",
    "print(\"\\nStep 3: Verifying the new CSV...\")\n",
    "verify_new_csv(output_csv_path)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780acb97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ped",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
